<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="First Workshop on Scholarly Document Processing">

  <title>1st Workshop on Scholarly Document Processing</title>

  <!-- Bootstrap core CSS -->
  <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- Fira Sans font -->
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans&display=swap" rel="stylesheet">

  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <!-- Custom styles for this template -->
  <link href="styles.css" rel="stylesheet">

  <!-- icons -->
  <link rel="stylesheet" href="./font-awesome-4.1.0/css/font-awesome.min.css">

</head>

<body>

  <!-- NAVBAR ================================================== -->

  <div class="navbar-wrapper">
    <div class="container">
      <div class="navbar navbar-inverse navbar-static-top" role="navigation">
        <div class="container">

          <!-- MENU BUTTON FOR SMALL SCREENS + LOGO ================================ -->

          <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="header-logo-link" href="index.html">
              <div class="header-logo">
                <span class="letter-highlight">S</span>cholarly
                <span class="letter-highlight">D</span>ocument
                <span class="letter-highlight">P</span>rocessing
                @ <span class="letter-highlight">EMNLP 2020</span>
              </div>
            </a>
          </div>

          <!-- MENU OPTIONS ================================================== -->

          <div class="navbar-collapse collapse pull-right">
            <ul class="nav navbar-nav">
              <li><a href="index.html">Home</a></li>
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Call for Papers <sup><mark>NEW!</mark></sup><b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="cfp.html">Call for Papers</a></li>
                  <li><a href="cfp.html#topics">Topics of Interest</a></li>
                  <li><a href="cfp.html#sharedtasks">Shared Tasks</a></li>
                  <li><a href="cfp.html#submission">Submission Information</a></li>
                  <li><a href="cfp.html#dates">Important Dates</a></li>
                  <li><a href="cfp.html#journal">Journal Extension</a></li>
                  <li><a href="cfp.html#keynotes">Keynote Speakers</a></li>
                  <li><a href="cfp.html#committees">Committees</a></li>
                </ul>
              </li>
              <li class="dropdown active">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Shared Tasks <sup><mark>NEW!</mark></sup><b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="sharedtasks.html">Call for Participation</a></li>
                  <li><a href="sharedtasks.html#clscisumm">CL-SciSumm</a></li>
                  <li><a href="sharedtasks.html#laysumm">CL-LaySumm</a></li>
                  <li><a href="sharedtasks.html#longsumm">LongSumm</a></li>
                  <li><a href="sharedtasks.html#register">Registration</a></li>
                  <li><a href="sharedtasks.html#dates">Important Dates</a></li>
                  <li><a href="sharedtasks.html#organizers">Organizers</a></li>
                </ul>
              </li>
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Program<b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="keynotespeakers.html">Keynotes</a></li>
                  <li><a href="program.html">Program</a></li>
                  <li><a href="accepted-papers.html">Accepted Papers-Research Track</a></li>
                </ul>
              </li>
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Committees<b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="organizingcommittee.html">Organizing Committee</a></li>
                  <li><a href="steeringcommittee.html">Steering Committee</a></li>
                  <li><a href="programcommittee.html">Program Committee</a></li>
                  <li><a href="contact.html">Contact Us</a></li>
                </ul>
              </li>
              <li><a href="previousworkshops.html">Other Workshops</a></li>
              <li><a href="https://2020.emnlp.org/">Venue</a></li>
            </ul>
          </div>

          <!-- MENU OPTIONS END ================================ -->

        </div>
      </div>
    </div>
  </div>

  <!-- MAIN CONTENT ============================================= -->

  <div class="container marketing navbar-spacing">

    <div class="row">
      <div class="col-md-12">

        <!-- CFP INTRODUCTION ================================================== -->

        <!-- <h1>The 6<sup>th</sup> Computational Linguistics Scientific Document Summarization Shared
          Task (CL-SciSumm 2020)</h1> -->

        <h1>Shared Tasks: Call for Participation</h1>

        <p>
          <a href="https://docs.google.com/forms/d/e/1FAIpQLScfHzByrog-k299qBuCp3SbPWcb905_kmOWMvHpDH57VLpVrg/viewform"><button type="button" class="btn btn-primary">Shared Tasks Registration</button></a>
        </p>

        <hr class="featurette-divider">

        <h2>Navigation</h2>

        <ul>
          <li>
            <a href="#clscisumm">CL-SciSumm 2020</a>
          </li>
          <li>
            <a href="#laysumm">CL-LaySumm 2020</a>
          </li>
          <li>
            <a href="#longsumm">LongSumm 2020</a>
          </li>
          <li>
            <a href="#register">Registration</a>
          </li>
          <li>
            <a href="#dates">Important Dates</a>
          </li>
          <li>
            <a href="#organizers">Organizing Committee</a>
          </li>
        </ul>

        <hr class="featurette-divider">

        <!-- CL-SciSumm ======================================================== -->

        <h2 id="clscisumm">CL-SciSumm 2020: The 6<sup>th</sup> Computational Linguistics Scientific Document Summarization Shared Task</h2>

        <p>
          CL-SciSumm is the first medium-scale shared task on scientific document summarization, with over 500 annotated
          documents. <a href="https://wing.comp.nus.edu.sg/~cl-scisumm2019/">Last year's CL-SciSumm shared task</a>
          introduced large scale training datasets, both annotated from ScisummNet and auto-annotated. For the task,
          Systems were provided with a Reference Paper (RP) and 10 or more Citing Papers (CPs) that all contain
          citations to the RP, which they used to summarise RP. This was evaluated against abstract and human written
          summaries on ROUGE. The shared task attracted 17 registrations and 9 final system submissions. This year,
          CL-SciSumm '20 will have two new tracks: <b><a href="#laysumm">LaySumm</a></b> and <b><a
              href="#longsumm">LongSumm</a></b>.
        </p>

        <h3>CL-SciSumm Task</h3>

        <p>
          The task is defined as follows:
        </p>

        <ul>
          <li>
            <strong>Given:</strong> A topic consisting of a Reference Paper (RP) and Citing Papers (CPs) that all contain citations to the RP. In each CP, the text spans (i.e., citances) have been identified that pertain to a particular citation to the RP.
          </li>
          <li>
            <strong>Task 1A:</strong> For each citance, identify the spans of text (cited text spans) in the RP that most accurately reflect the citance. These are of the granularity of a sentence fragment, a full sentence, or several consecutive sentences (no more than 5).
          </li>
          <li>
            <strong>Task 1B:</strong> For each cited text span, identify what facet of the paper it belongs to, from a predefined set of facets.
          </li>
          <li>
            <strong>Task 2 (optional bonus task):</strong> Finally, generate a structured summary of the RP from the cited text spans of the RP. The length of the summary should not exceed 250 words.
          </li>
        </ul>

        <h4>Evaluation</h4>

        <p>
          Task 1 will be scored by overlap of text spans measured by number of sentences in the system output vs the
          gold standard created by human annotators. Task 2 will be scored using the ROUGE family of metrics between (i)
          the system output and the gold standard summary from the reference spans (ii) the system output and the
          asbtract of the reference paper.
        </p>

        <h3>Corpus</h3>

        <p>
          The training and test sets from previous years can be downloaded from <a
            href="https://github.com/WING-NUS/scisumm-corpus">GitHub</a>.
        </p>

        <h3>Contact</h3>

        <p>
          For further information about this task and dataset, please contact:
        </p>

        <ul>
          <li>
            Muthu Kumar Chandrasekaran (Amazon), <a href="mailto:cmkumar087@gmail.com">cmkumar087@gmail.com</a>
          </li>
        </ul>

        <hr class="featurette-divider">

        <!-- LaySumm ========================================================= -->

        <h2 id="laysumm">CL-LaySumm 2020: The 1<sup>st</sup> Computational Linguistics Lay Summary Challenge Shared Task</h2>

        <p>
          To ensure and increase the relevance of science for all of society and not just a small group of niche
          practitioners, researchers have been increasingly tasked by funders and publishers to outline the scope of
          their research for a general public by writing a summary for a lay audience, or lay summary. The LaySumm
          summarization task considers automating this responsibility, by enabling systems to automatically generate lay
          summaries. 
          <!-- A lay summary explains, succinctly and without using technical jargon, what the overall scope, goal and potential impact of a scientific paper is. -->
        </p>

        <!-- <p>
          The corpus for this task will comprise full-text papers with lay summaries, in a variety of domains, and from
          a number of journals. Elsevier will make a collection of about 500 Lay Summaries available from a collection of journals, as well as the abstracts and full text of these journals.
        </p> -->
        <p>
          The CL-LaySumm Shared Task is to automatically produce Lay Summaries of technical (scientific research article) texts. A Lay Summary is defined as a textual summary intended for a non-technical audience. It is typically produced either by the authors or by a journalist or commentator. Examples are provided in the training data. The corpus will cover three distinct domains: epilepsy, archeology, and materials engineering.
        </p>

        <!-- <p>
          The Task will be to generate summaries that are representative of the content, comprehensible, and interesting
          to a lay audience. The intrinsic evaluation will be done by ROUGE. In addition, a subset of randomly selected
          summaries will undergo human evaluation by science journalists and communicators for comprehensiveness,
          legibility and interest.
        </p> -->
        <p>
          In more detail, a lay summary explains, succinctly and without using technical jargon, what the overall scope, goal and potential impact of a scientific paper is. It is typically about 70 - 100 words in length. The task is to generate summaries that are representative of the content, comprehensible, and interesting to a lay audience.
        </p>

        <p>
          The intrinsic evaluation will be done by ROUGE, using ROUGE-1, -2, and Skipgram metrics. In addition, a randomly selected subset of the summaries will undergo human evaluation by science journalists and communicators for comprehensiveness, legibility, and interest.
        </p>

        <p>
          All nominated entries will be invited to publish a paper in Open Access (Author-Payment Charges will be waived) in a selected Elsevier publication. Authors will be asked to provide an automatically generated lay summary of their paper, together with their contribution.
        </p>

        <h3>Lay Summary Task</h3>

        <p>
          The task is defined as follows:
        </p>

        <ul>
          <li>
            <strong>Given:</strong> A full-text paper, its Abstract, and a Lay Summary of a given paper
          </li>
          <li>
            <strong>Task:</strong> For each paper, generate a Lay Summary of the specified length
          </li>
        </ul>

        <h4>Evaluation</h4>

        <p>
          The Lay Summary Task will be scored by using several ROUGE metrics to compare the system output and the gold standard Lay Summary. As a follow-up to the intrinsic evaluation, we will crowdsource a number of automatically generated lay summaries to a panel of judges and a lay audience. Details of the crowdsourcing evaluation will be announced with the sharing of the final test corpus on July 15, 2020.
        </p>

        <h3>Corpus</h3>

        <p>
          The corpus for this task will comprise full-text papers with lay summaries, in a variety of domains, and from a number of journals. Elsevier will make available a collection of lay summaries from a multidisciplinary collection of journals, as well as the abstracts and full text of these journals. For a small sample dataset, see the task <a href="https://github.com/WING-NUS/scisumm-corpus/blob/master/README_Laysumm.md#sample-dataset">GitHub repository</a>. To obtain access to full the LaySumm (training and test) corpus, please send an email to <a href="mailto:a.dewaard@elsevier.com">a.dewaard@elsevier.com</a>. You will be emailed and asked to sign a contract that grants you research access to the full corpus of approximately 600 full-text articles, abstracts and lay summaries. A training corpus consisting of approximately 2/3 of the corpus will be made available directly; the full corpus will be available on the Test Set Release date, July 15, 2020.
        </p>

        <p>
          For any questions on the contracts or the corpus, please contact <a href="mailto:a.dewaard@elsevier.com">a.dewaard@elsevier.com</a>.
        </p>

        <h3>Contact</h3>

        <p>
          For further information about this data release, contact the following members of the SDP 2020 workshop organizing committee:
        </p>

        <ul>
          <li>
            Anita de Waard (Elsevier, VT), <a href="mailto:a.dewaard@elsevier.com">a.dewaard@elsevier.com</a>
          </li>
          <li>
            Eduard Hovy (LTI, CMU), <a href="mailto:hovy@cmu.edu">hovy@cmu.edu</a>
          </li>
        </ul>

        <hr class="featurette-divider">

        <!-- LongSumm ========================================================= -->

        <h2 id="longsumm">LongSumm 2020: Shared Task on Generating Long Summaries for Scientific Documents</h2>

        <!-- <p>
          The LongSumm Task focuses on generating long summaries of scientific articles which require expertise in a
          scientific domain. To this end, we created a training set that consists of 1705 extractive summaries, and 200
          abstractive summaries of NLP and Machine Learning scientific papers. These are drawn from papers based on
          video talks from associated conferences (TalkSumm) and from blogs created by NLP and ML researchers. In
          addition, we create a test set of 30 abstractive summaries. Each submission is judged against one reference
          summary (gold summary) on ROUGE and should not exceed 600 words.
        </p> -->

        <p>
          Most of the work on scientific document summarization focuses on generating relatively short summaries (abstract like). While such a length constraint can be sufficient for summarizing news articles, it is far from sufficient for summarizing scientific work. In fact, such a short summary resembles more to an abstract than to a summary that aims to cover all the salient information conveyed in a given text. Writing such summaries requires expertise and a deep understanding in a scientific domain, as can be found in some researchers blogs.
        </p>

        <p>
          The LongSumm task opted to leverage blogs created by researchers in the NLP and Machine learning communities and use these summaries as reference summaries to compare the submissions against.
        </p>

        <p>
          The corpus for this task includes a training set that consists of 1,705 extractive summaries, and around 700 abstractive summaries of NLP and Machine Learning scientific papers. These are drawn from papers based on video talks from associated conferences (<a href="https://arxiv.org/abs/1906.01351">Lev et al. 2019 TalkSumm</a>) and from blogs created by NLP and ML researchers. In addition, we create a test set of abstractive summaries. Each submission is judged against one reference summary (gold summary) on ROUGE and should not exceed 600 words.
        </p>

        <h3>Long Summary Task</h3>

        <p>
          The task is defined as follows:
        </p>

        <ul>
          <li>
            <strong>Given:</strong> For a detailed description of the provided data, please see the <a href="https://github.com/guyfe/LongSumm#training-data">LongSumm GitHub repository</a>
          </li>
          <li>
            <strong>Task:</strong> Generate abstractive and extractive summaries for scientific papers
          </li>
        </ul>

        <h4>Evaluation</h4>

        <p>
          The Long Summary Task will be scored by using several ROUGE metrics to compare the system output and the gold standard Lay Summary. The intrinsic evaluation will be done by ROUGE, using ROUGE-1, -2, -L and Skipgram metrics. In addition, a randomly selected subset of the summaries will undergo human evaluation.
        </p>

        <h3>Corpus</h3>

        <p>
          The training data is composed of abstractive and extractive summaries. To download both datasets, and for further details, see the <a href="https://github.com/guyfe/LongSumm#training-data">LongSumm GitHub repository</a>.
        </p>

        <p>
          The (blind) test dataset will be released on July 15, 2020.
        </p>

        <h3>Contact</h3>

        <p>
          For further information about this dataset please contact the organizers of the shared task:
        </p>

        <ul>
          <li>
            <a href="https://researcher.watson.ibm.com/researcher/view.php?person=il-SHMUELI">Michal Shmueli-Scheuer - IBM Research AI</a>
          </li>
          <li>
            <a href="https://researcher.watson.ibm.com/researcher/view.php?person=il-GUYF">Guy Feigenblat - IBM Research AI</a>
          </li>
        </ul>

        <hr class="featurette-divider">

        <!-- IMPORTANT DATES ========================================================= -->

        <h2 id="register">Registration</h2>

        <p>
          To register for participation in the shared tasks, please use <a href="https://docs.google.com/forms/d/e/1FAIpQLScfHzByrog-k299qBuCp3SbPWcb905_kmOWMvHpDH57VLpVrg/viewform">this registration form</a>.
        </p>

        <hr class="featurette-divider">

        <!-- IMPORTANT DATES ========================================================= -->

        <h2 id="dates">Important Dates</h2>

        <p>
          Please consult the <a href="index.html">SDP Workshop website</a> for official dates for the workshop. All submission deadlines are 11:59 PM AoE (Anywhere on Earth) Time Zone (UTC-12).
        </p>

        <table class="table table-striped">
          <thead>
            <tr>
              <th scope="col">Event</th>
              <th scope="col">Date</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Training Set Release</td>
              <td>Feb 15, 2020. An additional development set will be made available closer to the test set release date</td>
            </tr>
            <tr>
              <td>Deadline for Registration</td>
              <td> April 30 (remains open till evaluation window starts)<br /></td>
            </tr>
            <tr>
              <td>Test Set Release (Blind)</td>
              <td><del>July 1, 2020</del> July 15, 2020</td>
            </tr>
            <tr>
              <td>System Runs Due</td>
              <td><del>August 1, 2020</del> Aug 15, 2020 </td>
            </tr>
            <tr>
              <td>Preliminary System Reports Due in SoftConf</td>
              <td>August 16, 2020</td>
            </tr>
            <tr>
              <td>Camera-Ready Contributions Due in SoftConf</td>
              <td><del>August 31, 2020</del> Oct 10, 2020</td>
            </tr>
            <tr>
              <td>Participant Presentations at SDP 2020</td>
              <td><del>Nov 12</del> Nov 19, 2020</td>
            </tr>
          </tbody>
        </table>

        <hr class="featurette-divider">

        <!-- ORGANIZERS ================================================================= -->

        <h2 id="organizers">Organizing Committee</h2>

        <h3 class="featurette-name-heading"><a href="https://www.linkedin.com/in/muthukumarc87/">Muthu Kumar
            Chandrasekaran</a></h3>
        <p class="lead">Amazon, Seattle, US</p>
        <p>
          Muthu Kumar Chandrasekaran is a Research Scientist at Amazon, Seattle working on Natural language understanding. Previously he was a Scientist at SRI's International Artificial Intelligence Center. He completed his Ph.D. from NUS School of Computing. He is broadly interested in natural language processing, machine learning and their applications to information retrieval; specifically, in retrieving and organising information from asynchronous conversation media such as scholarly publications and discussion forums. He has been co-chairing the CL-SciSumm Shared Task series and the BIRNDL workshop series since 2014. He also reviews for ACL, EMNLP, NAACL, CoNLL and JCDL conferences. During his PhD he also interned at the Allen Institute for Artificial Intelligence's Semantic Scholar research and National Institute of Informatics, Tokyo.
        </p>

        <h3 class="featurette-name-heading"><a href="https://www.linkedin.com/in/anitadewaard/">Anita de Waard</a></h3>
        <p class="lead">Elsevier, USA</p>
        <p>
          Anita is VP of Research Collaborations, where her work focuses on working with academic and industry partners
          on projects pertaining to progressing modes and frameworks for scholarly communication. Since 1997, she has
          worked on bridging the gap between science publishing and computational and information technologies,
          collaborating with groups in Europe and the US. From 2006 onwards, de Waard has been working on a discourse
          analysis of scientific narrative, with an emphasis on finding key epistemic components in biological text and
          within that scope, helped start the TAC SciSumm workshops in 2013. She is a cofounder of Force11 and cofounder
          of the Research Data Alliance's group on data retrieval technologies.
        </p>

        <h3 class="featurette-name-heading"><a
            href="https://researcher.watson.ibm.com/researcher/view.php?person=il-GUYF">Guy Feigenblat</a></h3>
        <p class="lead">IBM Research AI, Haifa Research Lab, Israel</p>
        <p>
          Guy Feigenblat is a team leader at the Language and Retrieval group in IBM Research AI. Guy is interested in
          AI, NLP and Information Retrieval (IR) research. He currently leads projects focusing on automatic document
          summarization (query-based, generic, extractive, abstractive) for various domains and use cases. Guy is
          involved in the development of <a href="http://ibm.biz/sciencesum">IBM Science Summarizer</a>, a novel search
          engine for scientific literature. Guy holds a Ph.D. in computer science from Bar-Ilan University. He
          co-organized Stringology workshop 2012.
        </p>

        <h3 class="featurette-name-heading"><a href="https://www.sri.com/about/people/dayne-freitag">Dayne Freitag</a>
        </h3>
        <p class="lead">SRI International, San Diego, USA</p>
        <p>
          He is Program Director at SRI's Artificial Intelligence Center. He leads the Advanced Analytics group. His
          research seeks to apply artificial intelligence to information assimilation, management and exploitation.
          Freitag has served as principal investigator for a number of research projects including several large,
          multi-institutional efforts. His research goals have focused on the automation of data science; the automatic
          extension of mechanistic models through machine reading; knowledge federation over diverse information sources
          through data analytics and natural language processing; explaining the spread of ideas through online
          communities; and novel approaches to institutional knowledge management using controlled English. Freitag
          holds a B.A. in English literature from Reed College, and a Ph.D. in computer science from Carnegie Mellon
          University.
        </p>

        <h3 class="featurette-name-heading"><a href="https://www.cs.cmu.edu/~hovy/">Eduard Hovy</a></h3>
        <p class="lead">Research Professor, LTI, Carnegie Melon University</p>
        <p>
          His research includes work on computational semantics of human language (such as text analysis, event
          detection and coreference, text summarization and generation, question answering, discourse processing,
          ontologies, text mining, text annotation, and machine translation evaluation), aspects of social media (such
          as event detection and tracking, sentiment and opinion analysis, and author profile creation), analysis of the
          semantics of non-textual information such as tables, and aspects of digital government.
        </p>

        <h3 class="featurette-name-heading"><a
            href="https://researcher.watson.ibm.com/researcher/view.php?person=il-DAVIDKO">David Konopnicki</a></h3>
        <p class="lead">IBM Research AI, Haifa Research Lab, Israel</p>
        <p>
          David Konopnicki manages the Language and Retrieval group in IBM Research AI and is leading a variety of R&D
          projects: development of large-scale full-text search engines, building customer profiles from enterprise and
          social media sources, affective computing on conversations data and more. David leads the development of <a
            hef="http://ibm.biz/sciencesum">IBM Science Summarizer</a>, a novel search engine for scientific literature.
          David was a co-organizer of the THUM workshop at UMAP 2017, and the organizer of ISCOL 2018, and 2019.
        </p>

        <h3 class="featurette-name-heading"><a href="https://researcher.watson.ibm.com/researcher/view.php?person=il-SHMUELI">Michal Shmueli-Scheuer</a></h3>
        <p class="lead">IBM Research AI, Haifa Research Lab, Israel</p>
        <p>
          Dr. Michal Shmueli-Scheuer is a leader researcher in the Language and Retrieval research group (AI Language department) in IBM Research - Haifa, with over 12 years of industry experience. She holds a Ph.D (2009) degree in Information and Computer Science from the University of California, Irvine, USA. Her area of expertise is in the fields of conversational bots, affective computing, user modeling, large scale analytics, database, and information systems, focusing on user behavior analytics and information management on the web. She has published more than 30 academic papers in leading conferences, and journals, and book chapters. She has served as a PC member and a reviewer of numerous leading conferences and journals. Within IBM, she has lead numerous user modeling related projects and has been recognized for her significant contributions.
        </p>

      </div>
    </div>

    <!-- FOOTER ========================================== -->

    <hr><br />

    <footer>
      <div class="footer-wrapper">
        <div class="footer-left">
          <p>Contact: <a href="mailto:sdproc@googlegroups.com">sdproc@googlegroups.com</a></p>
          <p>Follow us: <a href="https://twitter.com/sdproc">https://twitter.com/SDProc</a></p>
          <p>&copy; 2020 Oak Ridge National Laboratory</p>
        </div>
        <div class="footer-right">
          <a href="#">Back to top</a>
        </div>
    </footer>

  </div>

  <!-- Bootstrap core JavaScript ================================================== -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
  <script src="./dist/js/bootstrap.min.js"></script>
  <script src="./assets/js/docs.min.js"></script>

</body>

</html>
